{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd0a63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 14:42:08.309098: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-23 14:42:08.450199: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-23 14:42:09.021709: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-23 14:42:09.021794: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-23 14:42:09.021803: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../..')\n",
    "from hamp_pred.src.input_prep.prepare_sequence import MultiChainOperator, SeqWindow\n",
    "from hamp_pred.src.input_prep.encode import MultiEncoder, OneHotEncoderSeq, RadianEncoder #, MixedEncoder, \n",
    "from hamp_pred.src.input_prep.encode import RadiousPhobosEncoder\n",
    "from hamp_pred.src.predictor_config import PredictionConfig #,SEQ_ENCODING_EXTERNAL DEFAULT_CONF, \n",
    "from hamp_pred.src.models.common.models import BaseConvolutionalWrapper #, BaseLinearWrapper\n",
    "from hamp_pred.src.predictor import Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd966887",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e41b843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data/input'\n",
    "\n",
    "# data set contains train and validation sets\n",
    "# the val set is used for eraly stopping \n",
    "data = f'{DATA_DIR}/af2_clean_model_1.p'\n",
    "data = pd.read_pickle(data)\n",
    "data['n_seq'] = data['n_seq'].apply(lambda x: x[1:-1])\n",
    "data['c_seq'] = data['c_seq'].apply(lambda x: x[1:-1])\n",
    "data['train_seq'] = data.apply(lambda x: x['n_seq'] + x['c_seq'], axis=1)\n",
    "assert all(data['train_seq'].str.len() == 22)\n",
    "\n",
    "# separate test set used to pick the best model\n",
    "#data_test = f'{DATA_DIR}/af_clean_model_test.p'\n",
    "#data_test = pd.read_pickle(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f12335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    3978\n",
       "val       994\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fdae1e",
   "metadata": {},
   "source": [
    "## Train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "690f1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(val, mod):\n",
    "    seqs = list(val.train_seq)\n",
    "    tr=[]\n",
    "    for n,r in val.iterrows():\n",
    "        tr.append(np.mean((r['rot'][0::2] + r['rot'][1::2]) / 2)/2)\n",
    "    res = mod.predict(seqs)\n",
    "    pr = []\n",
    "    for n,r in res.iterrows():\n",
    "        pr.append(np.mean(r['N_pred'])/2)\n",
    "        \n",
    "    return np.mean((np.array(tr)-np.array(pr)) **2 ) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc8ef27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, conf, version):\n",
    "    operator = MultiChainOperator(MultiEncoder([RadiousPhobosEncoder(), OneHotEncoderSeq()]), SeqWindow(11, 11), RadianEncoder(100),  SeqWindow(11, 11, null_char=[[0]]),\n",
    "                                          parallel=True)\n",
    "    conf = PredictionConfig(BaseConvolutionalWrapper, operator, conf)\n",
    "    mod = Predictor('hamp_rot', config=conf, version=version)\n",
    "    trained = mod.train(data)\n",
    "    return mod, trained\n",
    "\n",
    "def get_mod(conf=None, version=None):\n",
    "    operator = MultiChainOperator(MultiEncoder([RadiousPhobosEncoder(), OneHotEncoderSeq()]), SeqWindow(11, 11), RadianEncoder(100),  SeqWindow(11, 11, null_char=[[0]]),\n",
    "                                          parallel=True)\n",
    "    conf = PredictionConfig(BaseConvolutionalWrapper, operator, conf)\n",
    "    mod = Predictor('hamp_rot', config=conf, version=version)\n",
    "    return mod\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "992c4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_conf(data, tune=False):\n",
    "    \n",
    "    # data: train and val (val for the eraly stopping)\n",
    "    \n",
    "    data_val = data[data['class'] == 'val']\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    # parameters grid\n",
    "    kernels = [(3, 5, 7)]\n",
    "    layers = [5, 7]\n",
    "    lstm = [1, 2]\n",
    "    dense = [1, 3]\n",
    "    \n",
    "    for kern in kernels:\n",
    "        for l in layers:\n",
    "            for ls in lstm:\n",
    "                for d in dense:\n",
    "                    model_config = {\n",
    "                        'activation': 'tanh',\n",
    "                        'norm': True,\n",
    "                        'n_layers': l,\n",
    "                        'kernel_sizes': kern,\n",
    "                        'lstm': ls,\n",
    "                        'dense': d,\n",
    "                        'reshape_out': False,\n",
    "                        'epochs': 100\n",
    "                    }\n",
    "                    version = '_'.join([str(x) for x in [\"_\".join([str(i) for i in kern]), l, ls, d]])\n",
    "                    if tune:\n",
    "                        mod, trained = train(data, model_config, version)\n",
    "                    else:\n",
    "                        mod = get_mod(model_config, version)\n",
    "                        \n",
    "                    results[version] = (get_rmse(data_val, mod), model_config)\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08447003",
   "metadata": {},
   "source": [
    "## Tune hiperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c640d33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 14:42:12.316155: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-23 14:42:12.889427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7380 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 14:42:18.346106: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8204\n",
      "2023-04-23 14:42:18.595787: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-23 14:42:18.596325: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-23 14:42:18.596352: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-04-23 14:42:18.596897: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-23 14:42:18.597496: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 8s 130ms/sample - loss: 0.0341 - mae: 0.1056 - val_loss: 0.0244 - val_mae: 0.0992 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 0.0148 - mae: 0.0761 - val_loss: 0.0173 - val_mae: 0.0812 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 2s 26ms/sample - loss: 0.0115 - mae: 0.0694 - val_loss: 0.0161 - val_mae: 0.0754 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0085 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0823 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 0.0063 - mae: 0.0519 - val_loss: 0.0155 - val_mae: 0.0767 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 0.0052 - mae: 0.0482 - val_loss: 0.0175 - val_mae: 0.0812 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0044 - mae: 0.0446 - val_loss: 0.0156 - val_mae: 0.0764 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0036 - mae: 0.0404 - val_loss: 0.0153 - val_mae: 0.0724 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0028 - mae: 0.0355 - val_loss: 0.0167 - val_mae: 0.0787 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 0.0030 - mae: 0.0372 - val_loss: 0.0152 - val_mae: 0.0744 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0026 - mae: 0.0344 - val_loss: 0.0181 - val_mae: 0.0795 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0028 - mae: 0.0355 - val_loss: 0.0146 - val_mae: 0.0726 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 0.0027 - mae: 0.0355 - val_loss: 0.0150 - val_mae: 0.0726 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0028 - mae: 0.0364 - val_loss: 0.0148 - val_mae: 0.0728 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 0.0025 - mae: 0.0338 - val_loss: 0.0172 - val_mae: 0.0828 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0025 - mae: 0.0336 - val_loss: 0.0166 - val_mae: 0.0807 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0152 - val_mae: 0.0718 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0020 - mae: 0.0309 - val_loss: 0.0156 - val_mae: 0.0720 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0016 - mae: 0.0270 - val_loss: 0.0143 - val_mae: 0.0699 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0146 - val_mae: 0.0699 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 0.0017 - mae: 0.0281 - val_loss: 0.0151 - val_mae: 0.0715 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0017 - mae: 0.0278 - val_loss: 0.0146 - val_mae: 0.0698 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 2s 26ms/sample - loss: 0.0015 - mae: 0.0267 - val_loss: 0.0142 - val_mae: 0.0707 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0017 - mae: 0.0284 - val_loss: 0.0150 - val_mae: 0.0707 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 1s 23ms/sample - loss: 0.0016 - mae: 0.0274 - val_loss: 0.0143 - val_mae: 0.0704 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0149 - val_mae: 0.0703 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0157 - val_mae: 0.0724 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 0.0013 - mae: 0.0242 - val_loss: 0.0141 - val_mae: 0.0697 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0012 - mae: 0.0235 - val_loss: 0.0149 - val_mae: 0.0701 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0010 - mae: 0.0218 - val_loss: 0.0143 - val_mae: 0.0687 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 8.1426e-04 - mae: 0.0193 - val_loss: 0.0144 - val_mae: 0.0687 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 8.8232e-04 - mae: 0.0200 - val_loss: 0.0164 - val_mae: 0.0746 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0035 - mae: 0.0358 - val_loss: 0.0175 - val_mae: 0.0819 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0040 - mae: 0.0400 - val_loss: 0.0158 - val_mae: 0.0756 - lr: 0.0010\n",
      "Epoch 35/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 0.0027 - mae: 0.0340\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0027 - mae: 0.0339 - val_loss: 0.0143 - val_mae: 0.0695 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0014 - mae: 0.0243 - val_loss: 0.0140 - val_mae: 0.0675 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 9.2350e-04 - mae: 0.0205 - val_loss: 0.0139 - val_mae: 0.0675 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 7.2575e-04 - mae: 0.0184 - val_loss: 0.0139 - val_mae: 0.0673 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 6.3789e-04 - mae: 0.0174 - val_loss: 0.0139 - val_mae: 0.0673 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 1s 23ms/sample - loss: 5.5502e-04 - mae: 0.0164 - val_loss: 0.0139 - val_mae: 0.0673 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 5.2302e-04 - mae: 0.0160 - val_loss: 0.0138 - val_mae: 0.0675 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 5.1028e-04 - mae: 0.0159 - val_loss: 0.0139 - val_mae: 0.0673 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 4.4169e-04 - mae: 0.0149 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 3.9493e-04 - mae: 0.0141\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 3.9433e-04 - mae: 0.0141 - val_loss: 0.0138 - val_mae: 0.0675 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 3.7507e-04 - mae: 0.0137 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.7838e-04 - mae: 0.0138 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 3.4264e-04 - mae: 0.0132 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 1s 23ms/sample - loss: 3.5477e-04 - mae: 0.0134 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.9456e-04 - mae: 0.0141 - val_loss: 0.0138 - val_mae: 0.0673 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 3.8187e-04 - mae: 0.0139 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 3.4559e-04 - mae: 0.0132\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.4605e-04 - mae: 0.0133 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-05\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.4774e-04 - mae: 0.0133 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 3.5318e-04 - mae: 0.0134 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.4859e-04 - mae: 0.0133 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 3.3835e-04 - mae: 0.0131 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.5916e-04 - mae: 0.0135 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 3.4633e-04 - mae: 0.0133 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 3.3628e-04 - mae: 0.0131\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 3.3718e-04 - mae: 0.0132 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.4749e-04 - mae: 0.0133 - val_loss: 0.0139 - val_mae: 0.0672 - lr: 1.0000e-07\n",
      "1/1 [==============================] - 1s 922ms/step\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 7s 109ms/sample - loss: 0.0381 - mae: 0.1123 - val_loss: 0.0434 - val_mae: 0.1401 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 0.0155 - mae: 0.0774 - val_loss: 0.0202 - val_mae: 0.0920 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0105 - mae: 0.0651 - val_loss: 0.0163 - val_mae: 0.0801 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 0.0077 - mae: 0.0566 - val_loss: 0.0163 - val_mae: 0.0779 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0068 - mae: 0.0543 - val_loss: 0.0166 - val_mae: 0.0829 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0052 - mae: 0.0476 - val_loss: 0.0166 - val_mae: 0.0776 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0044 - mae: 0.0441 - val_loss: 0.0169 - val_mae: 0.0801 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0053 - mae: 0.0473 - val_loss: 0.0164 - val_mae: 0.0766 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0048 - mae: 0.0457 - val_loss: 0.0145 - val_mae: 0.0725 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0031 - mae: 0.0369 - val_loss: 0.0150 - val_mae: 0.0744 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 1s 23ms/sample - loss: 0.0031 - mae: 0.0375 - val_loss: 0.0166 - val_mae: 0.0820 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 2s 25ms/sample - loss: 0.0029 - mae: 0.0361 - val_loss: 0.0154 - val_mae: 0.0743 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0026 - mae: 0.0345 - val_loss: 0.0147 - val_mae: 0.0714 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0023 - mae: 0.0323 - val_loss: 0.0163 - val_mae: 0.0749 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0142 - val_mae: 0.0701 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0022 - mae: 0.0319 - val_loss: 0.0153 - val_mae: 0.0728 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0023 - mae: 0.0322 - val_loss: 0.0149 - val_mae: 0.0712 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0017 - mae: 0.0282 - val_loss: 0.0145 - val_mae: 0.0704 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0014 - mae: 0.0247 - val_loss: 0.0142 - val_mae: 0.0695 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 2s 25ms/sample - loss: 0.0012 - mae: 0.0234 - val_loss: 0.0149 - val_mae: 0.0732 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0142 - val_mae: 0.0693 - lr: 0.0010\n",
      "Epoch 22/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 0.0012 - mae: 0.0235\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 0.0012 - mae: 0.0235 - val_loss: 0.0145 - val_mae: 0.0713 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 9.1815e-04 - mae: 0.0203 - val_loss: 0.0139 - val_mae: 0.0689 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 6.7787e-04 - mae: 0.0178 - val_loss: 0.0141 - val_mae: 0.0686 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 5.9678e-04 - mae: 0.0168 - val_loss: 0.0139 - val_mae: 0.0687 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 5.4522e-04 - mae: 0.0161 - val_loss: 0.0140 - val_mae: 0.0686 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 5.3034e-04 - mae: 0.0159 - val_loss: 0.0139 - val_mae: 0.0692 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 4.7874e-04 - mae: 0.0152 - val_loss: 0.0141 - val_mae: 0.0686 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 4.5291e-04 - mae: 0.0148 - val_loss: 0.0141 - val_mae: 0.0685 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 4.6002e-04 - mae: 0.0148\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "63/63 [==============================] - 1s 24ms/sample - loss: 4.5660e-04 - mae: 0.0148 - val_loss: 0.0139 - val_mae: 0.0687 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 4.0164e-04 - mae: 0.0138 - val_loss: 0.0139 - val_mae: 0.0685 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.6427e-04 - mae: 0.0133 - val_loss: 0.0140 - val_mae: 0.0685 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.6308e-04 - mae: 0.0133 - val_loss: 0.0140 - val_mae: 0.0684 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.5019e-04 - mae: 0.0130 - val_loss: 0.0140 - val_mae: 0.0684 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.8221e-04 - mae: 0.0136 - val_loss: 0.0139 - val_mae: 0.0685 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.8767e-04 - mae: 0.0136 - val_loss: 0.0139 - val_mae: 0.0685 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 3.6058e-04 - mae: 0.0132\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.6008e-04 - mae: 0.0132 - val_loss: 0.0140 - val_mae: 0.0684 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 2s 25ms/sample - loss: 3.4442e-04 - mae: 0.0129 - val_loss: 0.0140 - val_mae: 0.0684 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.6466e-04 - mae: 0.0133 - val_loss: 0.0140 - val_mae: 0.0685 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 2s 24ms/sample - loss: 3.8087e-04 - mae: 0.0136 - val_loss: 0.0140 - val_mae: 0.0685 - lr: 1.0000e-06\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 10s 154ms/sample - loss: 0.0342 - mae: 0.1069 - val_loss: 0.0249 - val_mae: 0.1013 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 2s 31ms/sample - loss: 0.0155 - mae: 0.0776 - val_loss: 0.0157 - val_mae: 0.0758 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0102 - mae: 0.0639 - val_loss: 0.0163 - val_mae: 0.0779 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0080 - mae: 0.0573 - val_loss: 0.0162 - val_mae: 0.0799 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0075 - mae: 0.0575 - val_loss: 0.0165 - val_mae: 0.0783 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 2s 26ms/sample - loss: 0.0066 - mae: 0.0535 - val_loss: 0.0167 - val_mae: 0.0823 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 2s 26ms/sample - loss: 0.0050 - mae: 0.0470 - val_loss: 0.0157 - val_mae: 0.0744 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0040 - mae: 0.0417 - val_loss: 0.0157 - val_mae: 0.0741 - lr: 0.0010\n",
      "Epoch 9/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 0.0036 - mae: 0.0402\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0036 - mae: 0.0402 - val_loss: 0.0184 - val_mae: 0.0822 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 2s 31ms/sample - loss: 0.0024 - mae: 0.0327 - val_loss: 0.0140 - val_mae: 0.0696 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0017 - mae: 0.0280 - val_loss: 0.0141 - val_mae: 0.0698 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0141 - val_mae: 0.0697 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0014 - mae: 0.0253 - val_loss: 0.0142 - val_mae: 0.0699 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0013 - mae: 0.0243 - val_loss: 0.0140 - val_mae: 0.0698 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0013 - mae: 0.0240 - val_loss: 0.0141 - val_mae: 0.0697 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0012 - mae: 0.0233 - val_loss: 0.0141 - val_mae: 0.0705 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 0.0012 - mae: 0.0239\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0012 - mae: 0.0239 - val_loss: 0.0142 - val_mae: 0.0700 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0141 - val_mae: 0.0700 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0010 - mae: 0.0217 - val_loss: 0.0141 - val_mae: 0.0700 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0010 - mae: 0.0217 - val_loss: 0.0141 - val_mae: 0.0701 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 0.0010 - mae: 0.0216 - val_loss: 0.0141 - val_mae: 0.0700 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 9.8249e-04 - mae: 0.0213 - val_loss: 0.0142 - val_mae: 0.0700 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 9.7194e-04 - mae: 0.0212 - val_loss: 0.0141 - val_mae: 0.0700 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 9.9260e-04 - mae: 0.0214\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 9.9344e-04 - mae: 0.0214 - val_loss: 0.0141 - val_mae: 0.0700 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 2s 27ms/sample - loss: 9.6763e-04 - mae: 0.0211 - val_loss: 0.0141 - val_mae: 0.0700 - lr: 1.0000e-06\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 10s 158ms/sample - loss: 0.0376 - mae: 0.1117 - val_loss: 0.0240 - val_mae: 0.0964 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0154 - mae: 0.0771 - val_loss: 0.0214 - val_mae: 0.0927 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0106 - mae: 0.0657 - val_loss: 0.0166 - val_mae: 0.0793 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0092 - mae: 0.0615 - val_loss: 0.0176 - val_mae: 0.0801 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0071 - mae: 0.0549 - val_loss: 0.0165 - val_mae: 0.0777 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0059 - mae: 0.0513 - val_loss: 0.0159 - val_mae: 0.0742 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0047 - mae: 0.0461 - val_loss: 0.0170 - val_mae: 0.0797 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 2s 32ms/sample - loss: 0.0037 - mae: 0.0404 - val_loss: 0.0156 - val_mae: 0.0762 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0036 - mae: 0.0404 - val_loss: 0.0157 - val_mae: 0.0762 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0037 - mae: 0.0408 - val_loss: 0.0153 - val_mae: 0.0733 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0030 - mae: 0.0367 - val_loss: 0.0172 - val_mae: 0.0789 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 2s 32ms/sample - loss: 0.0038 - mae: 0.0409 - val_loss: 0.0149 - val_mae: 0.0720 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 0.0025 - mae: 0.0336 - val_loss: 0.0157 - val_mae: 0.0763 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0027 - mae: 0.0351 - val_loss: 0.0163 - val_mae: 0.0749 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0022 - mae: 0.0310 - val_loss: 0.0146 - val_mae: 0.0716 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0018 - mae: 0.0290 - val_loss: 0.0159 - val_mae: 0.0772 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0021 - mae: 0.0308 - val_loss: 0.0148 - val_mae: 0.0714 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0020 - mae: 0.0306 - val_loss: 0.0146 - val_mae: 0.0722 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 2s 32ms/sample - loss: 0.0016 - mae: 0.0268 - val_loss: 0.0145 - val_mae: 0.0705 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0152 - val_mae: 0.0749 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0019 - mae: 0.0292 - val_loss: 0.0155 - val_mae: 0.0723 - lr: 0.0010\n",
      "Epoch 22/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 0.0016 - mae: 0.0268\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0016 - mae: 0.0268 - val_loss: 0.0158 - val_mae: 0.0743 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 2s 32ms/sample - loss: 0.0011 - mae: 0.0227 - val_loss: 0.0143 - val_mae: 0.0703 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 2s 32ms/sample - loss: 7.1044e-04 - mae: 0.0184 - val_loss: 0.0142 - val_mae: 0.0695 - lr: 1.0000e-04\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 29ms/sample - loss: 6.5601e-04 - mae: 0.0177 - val_loss: 0.0144 - val_mae: 0.0693 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 5.9300e-04 - mae: 0.0170 - val_loss: 0.0143 - val_mae: 0.0691 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 5.8243e-04 - mae: 0.0167 - val_loss: 0.0144 - val_mae: 0.0692 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 6.0143e-04 - mae: 0.0170 - val_loss: 0.0144 - val_mae: 0.0693 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 2s 32ms/sample - loss: 6.6318e-04 - mae: 0.0179 - val_loss: 0.0142 - val_mae: 0.0692 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 5.1042e-04 - mae: 0.0157\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "63/63 [==============================] - 2s 32ms/sample - loss: 5.1058e-04 - mae: 0.0157 - val_loss: 0.0142 - val_mae: 0.0694 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 4.5153e-04 - mae: 0.0148 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 4.4010e-04 - mae: 0.0146 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 4.5369e-04 - mae: 0.0148 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 4.6763e-04 - mae: 0.0150 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 4.1344e-04 - mae: 0.0142 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 4.4157e-04 - mae: 0.0146 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 4.2458e-04 - mae: 0.0143\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 4.2562e-04 - mae: 0.0143 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 4.3045e-04 - mae: 0.0144 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 4.1693e-04 - mae: 0.0142 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 4.2354e-04 - mae: 0.0143 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 4.3098e-04 - mae: 0.0144 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 4.4670e-04 - mae: 0.0147 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 4.1384e-04 - mae: 0.0142 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 4.0860e-04 - mae: 0.0141\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 4.0874e-04 - mae: 0.0141 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 4.4622e-04 - mae: 0.0146 - val_loss: 0.0142 - val_mae: 0.0690 - lr: 1.0000e-07\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 8s 126ms/sample - loss: 0.0337 - mae: 0.1056 - val_loss: 0.0199 - val_mae: 0.0876 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0134 - mae: 0.0721 - val_loss: 0.0204 - val_mae: 0.0900 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0103 - mae: 0.0649 - val_loss: 0.0190 - val_mae: 0.0861 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0083 - mae: 0.0594 - val_loss: 0.0152 - val_mae: 0.0730 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0063 - mae: 0.0525 - val_loss: 0.0176 - val_mae: 0.0856 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0057 - mae: 0.0499 - val_loss: 0.0152 - val_mae: 0.0724 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0051 - mae: 0.0474 - val_loss: 0.0156 - val_mae: 0.0763 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0042 - mae: 0.0427 - val_loss: 0.0147 - val_mae: 0.0722 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0042 - mae: 0.0438 - val_loss: 0.0161 - val_mae: 0.0775 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0036 - mae: 0.0396 - val_loss: 0.0145 - val_mae: 0.0722 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 0.0029 - mae: 0.0358 - val_loss: 0.0176 - val_mae: 0.0787 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 0.0034 - mae: 0.0398 - val_loss: 0.0165 - val_mae: 0.0803 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0027 - mae: 0.0347 - val_loss: 0.0147 - val_mae: 0.0735 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0022 - mae: 0.0315 - val_loss: 0.0151 - val_mae: 0.0719 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0020 - mae: 0.0296 - val_loss: 0.0144 - val_mae: 0.0715 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0018 - mae: 0.0286 - val_loss: 0.0138 - val_mae: 0.0691 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0142 - val_mae: 0.0691 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 0.0016 - mae: 0.0270 - val_loss: 0.0144 - val_mae: 0.0704 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0018 - mae: 0.0287 - val_loss: 0.0147 - val_mae: 0.0712 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0023 - mae: 0.0322 - val_loss: 0.0144 - val_mae: 0.0707 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0019 - mae: 0.0290 - val_loss: 0.0139 - val_mae: 0.0682 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0149 - val_mae: 0.0705 - lr: 0.0010\n",
      "Epoch 23/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0277\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 0.0018 - mae: 0.0277 - val_loss: 0.0144 - val_mae: 0.0691 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 2s 32ms/sample - loss: 9.9796e-04 - mae: 0.0211 - val_loss: 0.0137 - val_mae: 0.0680 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 8.1153e-04 - mae: 0.0194 - val_loss: 0.0137 - val_mae: 0.0676 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 6.8140e-04 - mae: 0.0178 - val_loss: 0.0137 - val_mae: 0.0681 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 6.3020e-04 - mae: 0.0172 - val_loss: 0.0137 - val_mae: 0.0675 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 5.6687e-04 - mae: 0.0165 - val_loss: 0.0137 - val_mae: 0.0675 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 5.2582e-04 - mae: 0.0159 - val_loss: 0.0137 - val_mae: 0.0674 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 4.7203e-04 - mae: 0.0152 - val_loss: 0.0136 - val_mae: 0.0680 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 4.8177e-04 - mae: 0.0153\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "63/63 [==============================] - 2s 32ms/sample - loss: 4.8177e-04 - mae: 0.0153 - val_loss: 0.0136 - val_mae: 0.0677 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 4.2735e-04 - mae: 0.0145 - val_loss: 0.0136 - val_mae: 0.0673 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 4.2263e-04 - mae: 0.0144 - val_loss: 0.0136 - val_mae: 0.0674 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 4.0189e-04 - mae: 0.0139 - val_loss: 0.0136 - val_mae: 0.0674 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 4.1304e-04 - mae: 0.0142 - val_loss: 0.0136 - val_mae: 0.0674 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 4.1852e-04 - mae: 0.0144 - val_loss: 0.0136 - val_mae: 0.0673 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 3.8691e-04 - mae: 0.0138 - val_loss: 0.0136 - val_mae: 0.0674 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 3.7304e-04 - mae: 0.0136\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 3.7304e-04 - mae: 0.0136 - val_loss: 0.0137 - val_mae: 0.0674 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 4.2008e-04 - mae: 0.0143 - val_loss: 0.0136 - val_mae: 0.0674 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 3.8499e-04 - mae: 0.0137 - val_loss: 0.0136 - val_mae: 0.0674 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 3.6563e-04 - mae: 0.0135 - val_loss: 0.0136 - val_mae: 0.0674 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 3.6363e-04 - mae: 0.0134 - val_loss: 0.0136 - val_mae: 0.0674 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 2s 28ms/sample - loss: 3.9048e-04 - mae: 0.0139 - val_loss: 0.0136 - val_mae: 0.0674 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 4.0446e-04 - mae: 0.0141 - val_loss: 0.0136 - val_mae: 0.0674 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 4.0377e-04 - mae: 0.0141\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 4.0473e-04 - mae: 0.0141 - val_loss: 0.0136 - val_mae: 0.0674 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 2s 29ms/sample - loss: 3.9489e-04 - mae: 0.0140 - val_loss: 0.0136 - val_mae: 0.0674 - lr: 1.0000e-07\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f746a36c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 930ms/step\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 8s 130ms/sample - loss: 0.0358 - mae: 0.1085 - val_loss: 0.0645 - val_mae: 0.1735 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 2s 35ms/sample - loss: 0.0161 - mae: 0.0794 - val_loss: 0.0191 - val_mae: 0.0845 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0116 - mae: 0.0696 - val_loss: 0.0169 - val_mae: 0.0809 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0088 - mae: 0.0615 - val_loss: 0.0175 - val_mae: 0.0796 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 2s 35ms/sample - loss: 0.0083 - mae: 0.0593 - val_loss: 0.0164 - val_mae: 0.0775 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0054 - mae: 0.0485 - val_loss: 0.0165 - val_mae: 0.0784 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 2s 35ms/sample - loss: 0.0052 - mae: 0.0467 - val_loss: 0.0156 - val_mae: 0.0732 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0042 - mae: 0.0431 - val_loss: 0.0167 - val_mae: 0.0770 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0035 - mae: 0.0395 - val_loss: 0.0152 - val_mae: 0.0733 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0035 - mae: 0.0394 - val_loss: 0.0191 - val_mae: 0.0847 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 2s 31ms/sample - loss: 0.0030 - mae: 0.0365 - val_loss: 0.0156 - val_mae: 0.0751 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0030 - mae: 0.0373 - val_loss: 0.0155 - val_mae: 0.0741 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0024 - mae: 0.0332 - val_loss: 0.0153 - val_mae: 0.0747 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0024 - mae: 0.0335 - val_loss: 0.0165 - val_mae: 0.0751 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0020 - mae: 0.0301 - val_loss: 0.0147 - val_mae: 0.0723 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0019 - mae: 0.0291 - val_loss: 0.0168 - val_mae: 0.0808 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0018 - mae: 0.0286 - val_loss: 0.0146 - val_mae: 0.0700 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 2s 35ms/sample - loss: 0.0017 - mae: 0.0279 - val_loss: 0.0143 - val_mae: 0.0692 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0014 - mae: 0.0251 - val_loss: 0.0159 - val_mae: 0.0726 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0021 - mae: 0.0310 - val_loss: 0.0151 - val_mae: 0.0726 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0018 - mae: 0.0287 - val_loss: 0.0169 - val_mae: 0.0765 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0019 - mae: 0.0291 - val_loss: 0.0148 - val_mae: 0.0709 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0155 - val_mae: 0.0708 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0017 - mae: 0.0279 - val_loss: 0.0145 - val_mae: 0.0708 - lr: 0.0010\n",
      "Epoch 25/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 0.0014 - mae: 0.0257\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 0.0014 - mae: 0.0257 - val_loss: 0.0178 - val_mae: 0.0779 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 2s 35ms/sample - loss: 0.0011 - mae: 0.0223 - val_loss: 0.0143 - val_mae: 0.0680 - lr: 1.0000e-04\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 34ms/sample - loss: 6.3000e-04 - mae: 0.0171 - val_loss: 0.0140 - val_mae: 0.0678 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 2s 35ms/sample - loss: 5.5467e-04 - mae: 0.0160 - val_loss: 0.0140 - val_mae: 0.0677 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 5.0908e-04 - mae: 0.0154 - val_loss: 0.0140 - val_mae: 0.0676 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 4.6535e-04 - mae: 0.0148 - val_loss: 0.0140 - val_mae: 0.0682 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 4.7775e-04 - mae: 0.0150 - val_loss: 0.0140 - val_mae: 0.0680 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 4.4036e-04 - mae: 0.0145 - val_loss: 0.0141 - val_mae: 0.0676 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 4.2434e-04 - mae: 0.0142 - val_loss: 0.0141 - val_mae: 0.0676 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 3.6869e-04 - mae: 0.0132\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 3.6869e-04 - mae: 0.0132 - val_loss: 0.0140 - val_mae: 0.0680 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 4.1035e-04 - mae: 0.0139 - val_loss: 0.0140 - val_mae: 0.0676 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 3.6934e-04 - mae: 0.0132 - val_loss: 0.0140 - val_mae: 0.0677 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 2s 31ms/sample - loss: 3.4249e-04 - mae: 0.0128 - val_loss: 0.0140 - val_mae: 0.0677 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 3.7314e-04 - mae: 0.0133 - val_loss: 0.0140 - val_mae: 0.0677 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 2s 31ms/sample - loss: 3.4560e-04 - mae: 0.0128 - val_loss: 0.0140 - val_mae: 0.0677 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 3.8025e-04 - mae: 0.0134 - val_loss: 0.0140 - val_mae: 0.0677 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 3.2846e-04 - mae: 0.0125\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 3.2998e-04 - mae: 0.0126 - val_loss: 0.0140 - val_mae: 0.0677 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 3.3974e-04 - mae: 0.0127 - val_loss: 0.0140 - val_mae: 0.0677 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 3.3220e-04 - mae: 0.0125 - val_loss: 0.0140 - val_mae: 0.0677 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 3.2376e-04 - mae: 0.0124 - val_loss: 0.0140 - val_mae: 0.0677 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 3.1805e-04 - mae: 0.0124 - val_loss: 0.0140 - val_mae: 0.0677 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 2s 30ms/sample - loss: 3.2391e-04 - mae: 0.0124 - val_loss: 0.0140 - val_mae: 0.0677 - lr: 1.0000e-06\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f746ac73c70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 972ms/step\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 11s 174ms/sample - loss: 0.0403 - mae: 0.1149 - val_loss: 0.0195 - val_mae: 0.0885 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0135 - mae: 0.0719 - val_loss: 0.0204 - val_mae: 0.0903 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0105 - mae: 0.0644 - val_loss: 0.0185 - val_mae: 0.0827 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0103 - mae: 0.0646 - val_loss: 0.0171 - val_mae: 0.0783 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0084 - mae: 0.0602 - val_loss: 0.0160 - val_mae: 0.0787 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0060 - mae: 0.0511 - val_loss: 0.0152 - val_mae: 0.0769 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0054 - mae: 0.0473 - val_loss: 0.0164 - val_mae: 0.0760 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0040 - mae: 0.0417 - val_loss: 0.0151 - val_mae: 0.0732 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0037 - mae: 0.0407 - val_loss: 0.0159 - val_mae: 0.0788 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0037 - mae: 0.0405 - val_loss: 0.0152 - val_mae: 0.0738 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0028 - mae: 0.0348 - val_loss: 0.0144 - val_mae: 0.0718 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0025 - mae: 0.0336 - val_loss: 0.0145 - val_mae: 0.0719 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0022 - mae: 0.0309 - val_loss: 0.0150 - val_mae: 0.0713 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0023 - mae: 0.0329 - val_loss: 0.0144 - val_mae: 0.0721 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0026 - mae: 0.0343 - val_loss: 0.0149 - val_mae: 0.0706 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0024 - mae: 0.0320 - val_loss: 0.0148 - val_mae: 0.0710 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0024 - mae: 0.0321 - val_loss: 0.0166 - val_mae: 0.0754 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0019 - mae: 0.0293 - val_loss: 0.0142 - val_mae: 0.0693 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0152 - val_mae: 0.0746 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0143 - val_mae: 0.0693 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 2s 37ms/sample - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0139 - val_mae: 0.0692 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0143 - val_mae: 0.0697 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0146 - val_mae: 0.0712 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0140 - val_mae: 0.0691 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0013 - mae: 0.0240 - val_loss: 0.0143 - val_mae: 0.0712 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0012 - mae: 0.0234 - val_loss: 0.0150 - val_mae: 0.0702 - lr: 0.0010\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0012 - mae: 0.0234 - val_loss: 0.0141 - val_mae: 0.0713 - lr: 0.0010\n",
      "Epoch 28/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 0.0013 - mae: 0.0241\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0142 - val_mae: 0.0687 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 8.0232e-04 - mae: 0.0188 - val_loss: 0.0137 - val_mae: 0.0678 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 6.1284e-04 - mae: 0.0167 - val_loss: 0.0136 - val_mae: 0.0672 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 5.0744e-04 - mae: 0.0153 - val_loss: 0.0136 - val_mae: 0.0672 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 5.1693e-04 - mae: 0.0155 - val_loss: 0.0136 - val_mae: 0.0677 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 4.5572e-04 - mae: 0.0145 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 4.4552e-04 - mae: 0.0143 - val_loss: 0.0137 - val_mae: 0.0671 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 4.6069e-04 - mae: 0.0147 - val_loss: 0.0137 - val_mae: 0.0670 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 3.7692e-04 - mae: 0.0133\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.7692e-04 - mae: 0.0133 - val_loss: 0.0137 - val_mae: 0.0670 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 2s 37ms/sample - loss: 3.4934e-04 - mae: 0.0128 - val_loss: 0.0136 - val_mae: 0.0671 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 2s 37ms/sample - loss: 3.6538e-04 - mae: 0.0131 - val_loss: 0.0136 - val_mae: 0.0671 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.4754e-04 - mae: 0.0128 - val_loss: 0.0136 - val_mae: 0.0671 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.6513e-04 - mae: 0.0131 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.5865e-04 - mae: 0.0130 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.3731e-04 - mae: 0.0126 - val_loss: 0.0136 - val_mae: 0.0671 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 3.3369e-04 - mae: 0.0126\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.3369e-04 - mae: 0.0126 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.3990e-04 - mae: 0.0127 - val_loss: 0.0136 - val_mae: 0.0671 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 3.5318e-04 - mae: 0.0129 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.2484e-04 - mae: 0.0124 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.4130e-04 - mae: 0.0127 - val_loss: 0.0136 - val_mae: 0.0671 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.4493e-04 - mae: 0.0128 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.3111e-04 - mae: 0.0125 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 3.3129e-04 - mae: 0.0125\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.3129e-04 - mae: 0.0125 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.4812e-04 - mae: 0.0128 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-07\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.2531e-04 - mae: 0.0124 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-07\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 3.4004e-04 - mae: 0.0127 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-07\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 11s 174ms/sample - loss: 0.0395 - mae: 0.1140 - val_loss: 0.0655 - val_mae: 0.1756 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0145 - mae: 0.0760 - val_loss: 0.0227 - val_mae: 0.0967 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 2s 39ms/sample - loss: 0.0095 - mae: 0.0628 - val_loss: 0.0167 - val_mae: 0.0824 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0069 - mae: 0.0537 - val_loss: 0.0164 - val_mae: 0.0780 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0072 - mae: 0.0558 - val_loss: 0.0180 - val_mae: 0.0811 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0061 - mae: 0.0511 - val_loss: 0.0195 - val_mae: 0.0906 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 2s 39ms/sample - loss: 0.0067 - mae: 0.0562 - val_loss: 0.0162 - val_mae: 0.0755 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0042 - mae: 0.0428 - val_loss: 0.0156 - val_mae: 0.0749 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0037 - mae: 0.0408 - val_loss: 0.0152 - val_mae: 0.0740 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0031 - mae: 0.0371 - val_loss: 0.0147 - val_mae: 0.0710 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0027 - mae: 0.0352 - val_loss: 0.0148 - val_mae: 0.0727 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0027 - mae: 0.0352 - val_loss: 0.0149 - val_mae: 0.0728 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0026 - mae: 0.0343 - val_loss: 0.0144 - val_mae: 0.0708 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0023 - mae: 0.0324 - val_loss: 0.0148 - val_mae: 0.0730 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 0.0026 - mae: 0.0332 - val_loss: 0.0154 - val_mae: 0.0739 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0025 - mae: 0.0333 - val_loss: 0.0146 - val_mae: 0.0718 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 2s 39ms/sample - loss: 0.0020 - mae: 0.0302 - val_loss: 0.0143 - val_mae: 0.0703 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0017 - mae: 0.0278 - val_loss: 0.0143 - val_mae: 0.0691 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 2s 39ms/sample - loss: 0.0014 - mae: 0.0248 - val_loss: 0.0141 - val_mae: 0.0685 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0146 - val_mae: 0.0717 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0019 - mae: 0.0281 - val_loss: 0.0160 - val_mae: 0.0776 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0019 - mae: 0.0296 - val_loss: 0.0163 - val_mae: 0.0795 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0022 - mae: 0.0316 - val_loss: 0.0150 - val_mae: 0.0740 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0146 - val_mae: 0.0694 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 0.0014 - mae: 0.0246 - val_loss: 0.0141 - val_mae: 0.0701 - lr: 0.0010\n",
      "Epoch 26/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 0.0015 - mae: 0.0259\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0154 - val_mae: 0.0728 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 2s 39ms/sample - loss: 0.0011 - mae: 0.0219 - val_loss: 0.0135 - val_mae: 0.0672 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 2s 39ms/sample - loss: 6.9432e-04 - mae: 0.0178 - val_loss: 0.0135 - val_mae: 0.0672 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 6.1928e-04 - mae: 0.0168 - val_loss: 0.0136 - val_mae: 0.0678 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 5.5395e-04 - mae: 0.0160 - val_loss: 0.0136 - val_mae: 0.0669 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 2s 38ms/sample - loss: 4.9293e-04 - mae: 0.0151 - val_loss: 0.0135 - val_mae: 0.0670 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 4.6116e-04 - mae: 0.0146 - val_loss: 0.0135 - val_mae: 0.0669 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 4.1259e-04 - mae: 0.0139 - val_loss: 0.0135 - val_mae: 0.0670 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 4.4009e-04 - mae: 0.0143\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 4.4009e-04 - mae: 0.0143 - val_loss: 0.0136 - val_mae: 0.0670 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 3.8099e-04 - mae: 0.0134 - val_loss: 0.0135 - val_mae: 0.0668 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 3.5582e-04 - mae: 0.0129 - val_loss: 0.0135 - val_mae: 0.0668 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 2s 35ms/sample - loss: 3.5515e-04 - mae: 0.0129 - val_loss: 0.0135 - val_mae: 0.0669 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 3.6813e-04 - mae: 0.0131 - val_loss: 0.0135 - val_mae: 0.0669 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 2s 33ms/sample - loss: 3.5689e-04 - mae: 0.0129 - val_loss: 0.0135 - val_mae: 0.0669 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 3.4778e-04 - mae: 0.0127 - val_loss: 0.0135 - val_mae: 0.0669 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      " 0/63 [..............................] - ETA: 0s - loss: 3.4671e-04 - mae: 0.0127\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 3.4671e-04 - mae: 0.0127 - val_loss: 0.0135 - val_mae: 0.0668 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 3.6013e-04 - mae: 0.0129 - val_loss: 0.0135 - val_mae: 0.0668 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 3.6203e-04 - mae: 0.0129 - val_loss: 0.0135 - val_mae: 0.0669 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 3.5709e-04 - mae: 0.0129 - val_loss: 0.0135 - val_mae: 0.0668 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 3.8646e-04 - mae: 0.0134 - val_loss: 0.0135 - val_mae: 0.0668 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 2s 34ms/sample - loss: 3.4930e-04 - mae: 0.0128 - val_loss: 0.0135 - val_mae: 0.0668 - lr: 1.0000e-06\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "opt_res = opt_conf(data, tune=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4181008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3_5_7_7_2_3 4.23\n",
      "2 3_5_7_7_2_1 4.26\n",
      "3 3_5_7_7_1_1 4.26\n",
      "4 3_5_7_5_1_1 4.28\n",
      "5 3_5_7_5_1_3 4.31\n",
      "6 3_5_7_7_1_3 4.32\n",
      "7 3_5_7_5_2_1 4.32\n",
      "8 3_5_7_5_2_3 4.36\n"
     ]
    }
   ],
   "source": [
    "# kern, layers, lstm, dense\n",
    "for pos, (k, (v, model_config)) in enumerate(sorted(opt_res.items(), key=lambda item: item[1])):\n",
    "    if pos==0:\n",
    "        best_model_config = model_config\n",
    "        best_file = k\n",
    "        \n",
    "    print(pos+1, k, round(v, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0687c04",
   "metadata": {},
   "source": [
    "## Best Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5385783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'norm': True,\n",
       " 'n_layers': 7,\n",
       " 'kernel_sizes': (3, 5, 7),\n",
       " 'lstm': 2,\n",
       " 'dense': 3,\n",
       " 'reshape_out': False,\n",
       " 'epochs': 100,\n",
       " 'task': 'hamp_rot',\n",
       " 'version': '3_5_7_7_2_3',\n",
       " 'data_dir': '/home/users/sdunin/calc/HAMPpred/data/output/weights/hamp_rot/3_5_7_7_2_3'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f916320",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = get_mod(conf=best_model_config, version=best_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc953f",
   "metadata": {},
   "source": [
    "# PDB set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c8a096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_pickle(f'{DATA_DIR}/pdb_measure.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8ed8519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_pickle(os.path.join(DATA_DIR, 'pdb_measure.p'))\n",
    "test_data = test_data[~test_data.mutant]\n",
    "test_data.rename(columns={'seq1':'n_seq', 'seq2':'c_seq', 'n_list':'n_crick_mut', 'c_list':'c_crick_mut'}, inplace=True)\n",
    "test_data['n_seq'] = test_data['n_seq'].apply(lambda x: x[1:-1])\n",
    "test_data['c_seq'] = test_data['c_seq'].apply(lambda x: x[1:-1])\n",
    "test_data['train_seq'] = test_data.apply(lambda x: x['n_seq'] + x['c_seq'], axis=1)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daa9ee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "seq = []\n",
    "tr = []\n",
    "for n,r in test_data.iterrows():\n",
    "    seq.append(r['n_seq'] + r['c_seq'])\n",
    "    tr.append(np.mean((r['rot'][0::2] + r['rot'][1::2]) / 2)/2)\n",
    "res = mod.predict(seq)\n",
    "pr = []\n",
    "for n,r in res.iterrows():\n",
    "    pr.append(np.mean(r['N_pred'])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e0039a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'HAMPpred predictions')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "title_font_size = 12\n",
    "label_font_size = 10\n",
    "tick_font_size = 8\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(4, 4), dpi=200)\n",
    "\n",
    "colors = ['white' if i=='1_2l7i.pdb' else 'grey' for i in test_data.index]\n",
    "\n",
    "ax.scatter(pr, tr, color=colors, lw=0.75, edgecolors='k', s=50)\n",
    "\n",
    "ax.set_ylim(-26, 26)\n",
    "ax.set_xlim(-26, 26)\n",
    "ax.plot([0, 1], [0, 1], '--', transform=ax.transAxes, color='grey')\n",
    "\n",
    "ax.set_xlabel(r'Predicted rotation [$\\degree$]', size=label_font_size)\n",
    "ax.set_ylabel(r'Experimental structure rotation [$\\degree$]', size=label_font_size)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=tick_font_size)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=tick_font_size)\n",
    "ax.set_title(\"HAMPpred predictions\", size=title_font_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "161ec50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.302525585382851"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((np.asarray(tr)-np.asarray(pr)) **2 ) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b63dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c013c739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c55aece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6cd53a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a00dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
